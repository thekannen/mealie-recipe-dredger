# Recipe Dredger Configuration
# Copy this file to .env and customize for your setup

# =============================================================================
# CONNECTION SETTINGS
# =============================================================================

# --- Mealie Configuration ---
MEALIE_ENABLED=true
MEALIE_URL=http://192.168.1.X:9000
MEALIE_API_TOKEN=your_mealie_token_here

# --- Tandoor Configuration ---
TANDOOR_ENABLED=false
TANDOOR_URL=http://192.168.1.X:8080
TANDOOR_API_KEY=your_tandoor_key_here

# =============================================================================
# SCRAPER BEHAVIOR
# =============================================================================

# WARNING: DRY_RUN defaults to true for safety. Set to false to actually import.
DRY_RUN=true

# Logging verbosity (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Stop after importing this many recipes per site
TARGET_RECIPES_PER_SITE=50

# How many URLs to scan per site before giving up
SCAN_DEPTH=1000

# =============================================================================
# PERFORMANCE & RATE LIMITING
# =============================================================================

# Seconds to wait between requests to the same domain
CRAWL_DELAY=2.0

# Honor robots.txt crawl-delay directives
RESPECT_ROBOTS_TXT=true

# Days before sitemap cache expires (saves time on repeated runs)
CACHE_EXPIRY_DAYS=7

# =============================================================================
# OPTIONAL: CUSTOM SITE LIST
# =============================================================================

# Uncomment to use a custom site list instead of sites.json
# Path relative to container: /app/sites.json (mounted via volume)
# SITES=/app/sites.json

# OR: Comma-separated list (not recommended for large lists)
# SITES=https://example.com,https://another-blog.com
