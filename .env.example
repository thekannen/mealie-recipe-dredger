# Recipe Dredger Configuration
# Copy this file to .env and customize for your setup

# =============================================================================
# MEALIE CONNECTION
# =============================================================================
MEALIE_ENABLED=true
MEALIE_URL=http://192.168.1.X:9000
MEALIE_API_TOKEN=your_mealie_token_here

# Mealie import timeout in seconds
MEALIE_IMPORT_TIMEOUT=20
# Cleaner API timeout in seconds (GET/DELETE/PATCH against Mealie)
CLEANER_API_TIMEOUT=20
# Cleaner retries per Mealie API call
CLEANER_API_RETRIES=3
# Cleaner recipe page size for /api/recipes pagination (smaller can avoid timeouts)
CLEANER_RECIPES_PER_PAGE=250
# Delay between cleaner page retry attempts (seconds)
CLEANER_PAGE_RETRY_DELAY=1.5

# =============================================================================
# RUNTIME BEHAVIOR
# =============================================================================

# Dredger mode safety: defaults to true; set false for live import.
DRY_RUN=true

# Logging verbosity (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Optional entrypoint overrides (Docker compose already sets sensible defaults)
# TASK=dredger
# RUN_MODE=once
# RUN_INTERVAL_SECONDS=21600
# RUN_MODE=schedule
# RUN_SCHEDULE_DAY=7
# RUN_SCHEDULE_TIME=03:00

# Repeatable site-alignment (diff mode):
# When enabled, dredger compares baseline hosts vs current hosts and only prunes
# recipes from domains removed in that diff.
ALIGN_RECIPES_WITH_SITES=false
# Optional static baseline file (same JSON format as sites.json). If unset, a
# rolling baseline snapshot is maintained in data/site_alignment_hosts.json.
# ALIGN_SITES_BASELINE_FILE=/app/sites.json
# Optional override for the rolling baseline snapshot path.
# ALIGN_SITES_STATE_FILE=/app/data/site_alignment_hosts.json
# Include recipes with missing source URL fields in prune candidates.
ALIGN_SITES_INCLUDE_MISSING_SOURCE=false
# Log at most this many candidate recipes during each alignment run.
ALIGN_SITES_PREVIEW_LIMIT=50
# Timeout for alignment calls to Mealie.
ALIGN_SITES_TIMEOUT=20
# For TASK=align-sites runs: when true, apply deletions (default is dry-run).
# Safety: when true, also set ALIGN_SITES_BASELINE_FILE to keep pruning diff-scoped.
ALIGN_SITES_APPLY=false

# =============================================================================
# SCRAPE CONTROL
# =============================================================================
TARGET_RECIPES_PER_SITE=50
SCAN_DEPTH=1000

# =============================================================================
# PERFORMANCE & RATE LIMITING
# =============================================================================
CRAWL_DELAY=2.0
RESPECT_ROBOTS_TXT=true
CACHE_EXPIRY_DAYS=7

# Retry queue behavior for transient failures (timeouts, 429, 5xx)
MAX_RETRY_ATTEMPTS=3
# Precheck existing Mealie library by canonical source URL before import
IMPORT_PRECHECK_DUPLICATES=true
# Parallel Mealie import requests (higher = faster but more server load)
IMPORT_WORKERS=2
# Abort current site early after repeated Mealie HTTP 5xx import failures (0 disables)
SITE_IMPORT_FAILURE_THRESHOLD=3

# Language filter
# Keep imports to this language (ISO code, e.g. en, es, fr)
TARGET_LANGUAGE=en
# Enable language filtering during import verification
LANGUAGE_FILTER_ENABLED=true
# If true, pages with unknown language are rejected (stricter)
LANGUAGE_DETECTION_STRICT=true
# Minimum confidence for text-based language detection (0.0-1.0)
LANGUAGE_MIN_CONFIDENCE=0.70
# Cleaner removes existing recipes that don't match TARGET_LANGUAGE
CLEANER_REMOVE_NON_TARGET_LANGUAGE=true

# Cleaner worker count
MAX_WORKERS=2

# Cleaner behavior: rename salvageable "how-to" names instead of deleting.
CLEANER_RENAME_SALVAGE=true
# Cleaner behavior: dedupe recipes that share the same canonical source URL
CLEANER_DEDUPE_BY_SOURCE=true

# =============================================================================
# SITE SOURCE OVERRIDE (OPTIONAL)
# =============================================================================
# Path to a JSON file (absolute or relative) OR comma-separated URLs.
# In Docker, entrypoint defaults SITES to /app/data/sites.json and seeds it
# one time from bundled /app/sites.json if missing.
# SITES=/app/data/sites.json
# SITES=https://example.com,https://another-blog.com
